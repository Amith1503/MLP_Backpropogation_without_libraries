{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING THE TRAINING DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READING THE TRAINING DATA AND SAMPLES FROM CSV\n",
    "\n",
    "columns=[]\n",
    "for i in range (0,784):\n",
    "    columns.append(i)\n",
    "    \n",
    "train_data=pd.read_csv(\"/home/amith/Desktop/ECE657_Ass/train_data.csv\",names=columns)\n",
    "\n",
    "labels_data=pd.read_csv(\"/home/amith/Desktop/ECE657_Ass/train_labels.csv\",names=[\"class1\",\"class 2\",\"class 3\",\"class 4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCATINATING FOR SHUFFLING THE DATASET\n",
    "\n",
    "df= [train_data,labels_data]\n",
    "con_df=pd.concat(df,axis=1)\n",
    "\n",
    "\n",
    "# SHUFFLING THE DATASET\n",
    "\n",
    "shuffled_data=con_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# TRAIN AND TEST SET SPLIT\n",
    "\n",
    "X_train=shuffled_data.iloc[0:20000,0:784].values\n",
    "Y_train=shuffled_data.iloc[0:20000,784:].values\n",
    "\n",
    "X_val=shuffled_data.iloc[20000:,0:784].values\n",
    "Y_val=shuffled_data.iloc[20000:,784:].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAINING THE DATASET WITHOUT LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Weights Initializer Function\n",
    "\n",
    "def rand_weights():\n",
    "    tot_layers=[784,112,4]\n",
    "    \n",
    "    # Random First layer weights and bias (Dimensions of weights would be (tot_layers[0],tot_layers[1]))\n",
    "    W1= np.random.randn(tot_layers[0],tot_layers[1])\n",
    "    b1= np.random.randn(tot_layers[1])\n",
    "    \n",
    "    # Random last layer weights and bias (Dimensions of weights would be (tot_layers[1],tot_layers[2]))\n",
    "    W2= np.random.randn(tot_layers[1],tot_layers[2])\n",
    "    b2= np.random.randn(tot_layers[2])\n",
    "    \n",
    "    return W1,b1,W2,b2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACTIVATION FUNCTIONS\n",
    "\n",
    "# FIRST LAYER (HIDDEN LAYER ACTIVATION FUNCTION)\n",
    "def sigmoid(data):\n",
    "    return (1/(1+np.exp(-data)))\n",
    "\n",
    "# OUTPUT LAYER ACTIVATION FUNCTION\n",
    "def softmax(data):\n",
    "    exponential = np.exp(data)\n",
    "    return exponential / exponential.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS CALCULATION\n",
    "\n",
    "# cross-entropy loss function\n",
    "''' Since the output was one hot encoded and since it was a multi class classification problem cross-entropy loss\n",
    "loss function is used'''\n",
    "\n",
    "def cal_loss(y,y_hat):\n",
    "    n=len(y)\n",
    "    return 1/n * np.sum(-y * np.log(y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict, and round the predict to get one hot encoded values and Accuracy function\n",
    "def round_y_pred(y_pred):\n",
    "    ''' \n",
    "    Taking the index of the highest probablity and changing that index to 1 and rest to zero. This ensure that\n",
    "    y_predict is one hot encoded values\n",
    "    '''\n",
    "    zeros_ypred=np.zeros((len(y_pred),4)) \n",
    "    ypred_index=np.argmax(y_pred,axis=1)\n",
    "    \n",
    "    for i in range (len(y_pred)):\n",
    "        zeros_ypred[i][ypred_index[i]]=1\n",
    "    \n",
    "    return zeros_ypred\n",
    "    \n",
    "\n",
    "def predict(X_test,W1,b1,W2,b2):\n",
    "    '''\n",
    "    Predicts on a test data\n",
    "    '''\n",
    "    Z1 = np.dot(X_test, W1) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    Z2 = np.dot(A1, W2) + b2\n",
    "    pred = softmax(Z2)\n",
    "    \n",
    "    y_pred= round_y_pred(pred)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def accuracy(y_true, y_pred_1):\n",
    "    ''' \n",
    "    Accuracy function as given by instructors\n",
    "    '''\n",
    "    y_pred=round_y_pred(y_pred_1)\n",
    "    if not (len(y_true) == len(y_pred)):\n",
    "        print('Size of predicted and true labels not equal.')\n",
    "        return 0.0\n",
    "\n",
    "    corr = 0\n",
    "    for i in range(0,len(y_true)):\n",
    "        corr += 1 if (y_true[i] == y_pred[i]).all() else 0\n",
    "\n",
    "    return corr/len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING FUNCTION\n",
    "\n",
    "def train(lr,epoch,x_train,y_train,W1,b1,W2,b2):\n",
    "    \n",
    "    learning_rate= lr\n",
    "    error_loss=[]\n",
    "    \n",
    "    for i in range (epoch):\n",
    "        \n",
    "        # Forward_propogation\n",
    "\n",
    "        Z1=np.dot(x_train,W1)+b1\n",
    "        A1=sigmoid(Z1)\n",
    "        Z2=np.dot(A1,W2)+b2\n",
    "        y_hat= softmax(Z2)\n",
    "\n",
    "        # LOSS CALCULATION AFTER EACH FORWARD PASS AND CALCULATES TRAINING ACCURACY WITH ONE HOT ENCODED VALUES\n",
    "        \n",
    "        loss= cal_loss(y_train,y_hat)\n",
    "        train_acc= accuracy(y_train,y_hat)\n",
    "        print(\"EPOCH : \",(i+1),\" LOSS_VALUE : \",loss, \" TRAINING ACCURACY: \",train_acc)\n",
    "        error_loss.append(loss)\n",
    "        \n",
    "         # BACKWARD PROPOGATION\n",
    "\n",
    "        ''' LAST LAYER UPDATE EXPLINATION\n",
    "        \n",
    "         dl/dw2 = dl/yhat * dyhat/dz2 *dz2/dw2  ......1\n",
    "         dl/dz2 =  dl/yhat * dyhat/dz2 ......... 2\n",
    "\n",
    "         where\n",
    "         dl/yhat = derivation of loss function\n",
    "         dyhat/dz2 = derivation of activation with input as y_hat (a2)\n",
    "\n",
    "         Z2 = A1 * W2\n",
    "         dz2/dw2 = A1 .......... 3\n",
    "\n",
    "         Substituting 2 and 3 in 1\n",
    "         dl/dw2= dl/dz2 * A1  (dimension= 112 *4)\n",
    "\n",
    "         Bias B2\n",
    "         dl/db2=dl/dyhat * dyhat/dZ2 * dz2/dB2 ...........4\n",
    "         Z2= A1.W2 +B2\n",
    "         dZ2/dB2= 1  ..........5\n",
    "\n",
    "         Substituting 5 and 2 in eq4\n",
    "         dl/db2=dl/dz2\n",
    "\n",
    "         '''\n",
    "        # Weight W2\n",
    "\n",
    "        dl_dz2 =  y_hat - y_train        #DL/DZ2= dl_y_hat * dy_hat_sigmoid\n",
    "        dz2_dw2 = A1\n",
    "        dl_dw2=  np.dot (dz2_dw2.T,dl_dz2)\n",
    "        \n",
    "         # Bias b2\n",
    "            \n",
    "        dl_db2= dl_dz2\n",
    "\n",
    "\n",
    "        ''' \n",
    "         FIRST LAYER UPDATE EXPLINATION\n",
    "         dl/dw1 = dl/yhat * dyhat/dz2 *dz2/da1 * da1/dz1 * dz1/dw1  ......1\n",
    "         dl/dz2 =  dl/yhat * dyhat/dz2 ......... 2\n",
    "         Z2 = A1 * W2\n",
    "         dz2/da1= W2 .......3\n",
    "\n",
    "         Z1=X_train * W1\n",
    "         dz1/dw1= X_train .......... 4\n",
    "\n",
    "         da1/dz1= derivation of activation with input as z1 .... 5\n",
    "\n",
    "\n",
    "         Substituting 2 , 3 , 4 in 1\n",
    "         dl/dw1= dl/dz2 * W2 *  da1/dz1 * X_train (dimension= 784 * 112)\n",
    "\n",
    "         BIAS B1\n",
    "         dl/db1 = dl/yhat * dyhat/dz2 * dz2/da1 * da1/dz1 * dz1/db1 ...7\n",
    "         dz1/db1 =1.... 6\n",
    "\n",
    "         substituting 5,2,3,6 in 7\n",
    "\n",
    "         dl/db1= dl/z2 * W2 *  da1/dz1\n",
    "\n",
    "\n",
    "         '''\n",
    "        # Weight W1\n",
    "        \n",
    "        dz2_da1 = W2\n",
    "        dl_a1= np.dot(dl_dz2 , dz2_da1.T)  # dimension= ((20000 , 4)*( 4 *112)) = 20000,112\n",
    "        da1_dz1= sigmoid(Z1) * (1-sigmoid(Z1)) # derivation of activation with input as z1 dim= (20000,112)\n",
    "        dl_dw1=np.dot(X_train.T,da1_dz1* dl_a1 ) # change in weights wrt W1 dim_xtrain= 20000,784 fin dim=784*112\n",
    "\n",
    "        #Bias b1\n",
    "\n",
    "        dl_db1= dl_a1 * da1_dz1\n",
    "\n",
    "\n",
    "\n",
    "         # WEIGHTS UPDATE AFTER EACH EPOCH\n",
    "\n",
    "        W2= W2 - learning_rate* dl_dw2\n",
    "        b2= b2 - learning_rate* dl_db2.sum(axis=0)\n",
    "        W1= W1 - learning_rate* dl_dw1\n",
    "        b1= b1 - learning_rate* dl_db1.sum(axis=0)\n",
    "\n",
    "\n",
    "    \n",
    "    return error_loss,W1,b1,W2,b2\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  1  LOSS_VALUE :  7.3225894253460195  TRAINING ACCURACY:  0.34775\n",
      "EPOCH :  2  LOSS_VALUE :  164.62112665903607  TRAINING ACCURACY:  0.40095\n",
      "EPOCH :  3  LOSS_VALUE :  59.121902563628325  TRAINING ACCURACY:  0.2398\n",
      "EPOCH :  4  LOSS_VALUE :  58.95705926085355  TRAINING ACCURACY:  0.2488\n",
      "EPOCH :  5  LOSS_VALUE :  59.25805764396397  TRAINING ACCURACY:  0.2391\n",
      "EPOCH :  6  LOSS_VALUE :  54.14273286132177  TRAINING ACCURACY:  0.2723\n",
      "EPOCH :  7  LOSS_VALUE :  13.089579149570044  TRAINING ACCURACY:  0.23985\n",
      "EPOCH :  8  LOSS_VALUE :  22.937658197316583  TRAINING ACCURACY:  0.32815\n",
      "EPOCH :  9  LOSS_VALUE :  23.13705803311059  TRAINING ACCURACY:  0.50215\n",
      "EPOCH :  10  LOSS_VALUE :  13.422152499090263  TRAINING ACCURACY:  0.23915\n",
      "EPOCH :  11  LOSS_VALUE :  24.545493003678537  TRAINING ACCURACY:  0.2413\n",
      "EPOCH :  12  LOSS_VALUE :  31.894778246949244  TRAINING ACCURACY:  0.31125\n",
      "EPOCH :  13  LOSS_VALUE :  21.04952479358622  TRAINING ACCURACY:  0.2488\n",
      "EPOCH :  14  LOSS_VALUE :  26.561293783042714  TRAINING ACCURACY:  0.27175\n",
      "EPOCH :  15  LOSS_VALUE :  41.454969005269184  TRAINING ACCURACY:  0.2723\n",
      "EPOCH :  16  LOSS_VALUE :  40.159511032677  TRAINING ACCURACY:  0.2398\n",
      "EPOCH :  17  LOSS_VALUE :  17.722568428626612  TRAINING ACCURACY:  0.27155\n",
      "EPOCH :  18  LOSS_VALUE :  23.922148660936507  TRAINING ACCURACY:  0.50745\n",
      "EPOCH :  19  LOSS_VALUE :  12.650188176145495  TRAINING ACCURACY:  0.23995\n",
      "EPOCH :  20  LOSS_VALUE :  19.70885164145416  TRAINING ACCURACY:  0.2774\n",
      "EPOCH :  21  LOSS_VALUE :  31.872665983752082  TRAINING ACCURACY:  0.27255\n",
      "EPOCH :  22  LOSS_VALUE :  46.931999560071375  TRAINING ACCURACY:  0.2488\n",
      "EPOCH :  23  LOSS_VALUE :  20.77779691852101  TRAINING ACCURACY:  0.2559\n",
      "EPOCH :  24  LOSS_VALUE :  24.896559543917654  TRAINING ACCURACY:  0.2724\n",
      "EPOCH :  25  LOSS_VALUE :  21.43750253912108  TRAINING ACCURACY:  0.29545\n",
      "EPOCH :  26  LOSS_VALUE :  15.979816450528  TRAINING ACCURACY:  0.23915\n",
      "EPOCH :  27  LOSS_VALUE :  23.005245368727174  TRAINING ACCURACY:  0.4659\n",
      "EPOCH :  28  LOSS_VALUE :  19.971460003260145  TRAINING ACCURACY:  0.5081\n",
      "EPOCH :  29  LOSS_VALUE :  7.956917025941564  TRAINING ACCURACY:  0.6016\n",
      "EPOCH :  30  LOSS_VALUE :  3.1762744838971284  TRAINING ACCURACY:  0.6844\n",
      "EPOCH :  31  LOSS_VALUE :  16.068010115485507  TRAINING ACCURACY:  0.48165\n",
      "EPOCH :  32  LOSS_VALUE :  12.725321142212042  TRAINING ACCURACY:  0.7386\n",
      "EPOCH :  33  LOSS_VALUE :  5.433848451468163  TRAINING ACCURACY:  0.4999\n",
      "EPOCH :  34  LOSS_VALUE :  11.71507323505259  TRAINING ACCURACY:  0.35735\n",
      "EPOCH :  35  LOSS_VALUE :  4.29167098269026  TRAINING ACCURACY:  0.51075\n",
      "EPOCH :  36  LOSS_VALUE :  5.8752372044638825  TRAINING ACCURACY:  0.49175\n",
      "EPOCH :  37  LOSS_VALUE :  14.18813320759974  TRAINING ACCURACY:  0.6385\n",
      "EPOCH :  38  LOSS_VALUE :  4.586017440616888  TRAINING ACCURACY:  0.50295\n",
      "EPOCH :  39  LOSS_VALUE :  3.691416857256408  TRAINING ACCURACY:  0.44805\n",
      "EPOCH :  40  LOSS_VALUE :  7.653692800018844  TRAINING ACCURACY:  0.7308\n",
      "EPOCH :  41  LOSS_VALUE :  3.2764599607098175  TRAINING ACCURACY:  0.7109\n",
      "EPOCH :  42  LOSS_VALUE :  7.92132195073987  TRAINING ACCURACY:  0.72525\n",
      "EPOCH :  43  LOSS_VALUE :  3.1498039165663223  TRAINING ACCURACY:  0.7147\n",
      "EPOCH :  44  LOSS_VALUE :  7.825483690033947  TRAINING ACCURACY:  0.72695\n",
      "EPOCH :  45  LOSS_VALUE :  3.0483031635755973  TRAINING ACCURACY:  0.71495\n",
      "EPOCH :  46  LOSS_VALUE :  7.340774550000605  TRAINING ACCURACY:  0.72325\n",
      "EPOCH :  47  LOSS_VALUE :  3.5453116087269736  TRAINING ACCURACY:  0.7158\n",
      "EPOCH :  48  LOSS_VALUE :  6.842210936883378  TRAINING ACCURACY:  0.72505\n",
      "EPOCH :  49  LOSS_VALUE :  3.9024748430458454  TRAINING ACCURACY:  0.7147\n",
      "EPOCH :  50  LOSS_VALUE :  5.992748435139415  TRAINING ACCURACY:  0.7242\n",
      "EPOCH :  51  LOSS_VALUE :  4.774355580479549  TRAINING ACCURACY:  0.7152\n",
      "EPOCH :  52  LOSS_VALUE :  5.78142990896437  TRAINING ACCURACY:  0.7263\n",
      "EPOCH :  53  LOSS_VALUE :  4.713534817757736  TRAINING ACCURACY:  0.68925\n",
      "EPOCH :  54  LOSS_VALUE :  3.8345368977231447  TRAINING ACCURACY:  0.7238\n",
      "EPOCH :  55  LOSS_VALUE :  6.795178710778688  TRAINING ACCURACY:  0.7148\n",
      "EPOCH :  56  LOSS_VALUE :  3.303756368208955  TRAINING ACCURACY:  0.7365\n",
      "EPOCH :  57  LOSS_VALUE :  4.756494912003355  TRAINING ACCURACY:  0.71705\n",
      "EPOCH :  58  LOSS_VALUE :  4.468859286917412  TRAINING ACCURACY:  0.73875\n",
      "EPOCH :  59  LOSS_VALUE :  4.873317532299836  TRAINING ACCURACY:  0.7237\n",
      "EPOCH :  60  LOSS_VALUE :  4.686472166105023  TRAINING ACCURACY:  0.73895\n",
      "EPOCH :  61  LOSS_VALUE :  3.696712152097132  TRAINING ACCURACY:  0.7201\n",
      "EPOCH :  62  LOSS_VALUE :  3.3821789909695625  TRAINING ACCURACY:  0.7676\n",
      "EPOCH :  63  LOSS_VALUE :  1.8368118976876628  TRAINING ACCURACY:  0.74425\n",
      "EPOCH :  64  LOSS_VALUE :  2.413891740671053  TRAINING ACCURACY:  0.87925\n",
      "EPOCH :  65  LOSS_VALUE :  0.9081948803140788  TRAINING ACCURACY:  0.9318\n",
      "EPOCH :  66  LOSS_VALUE :  0.7854840190197178  TRAINING ACCURACY:  0.9345\n",
      "EPOCH :  67  LOSS_VALUE :  0.6783015436051879  TRAINING ACCURACY:  0.9373\n",
      "EPOCH :  68  LOSS_VALUE :  0.5575825024675738  TRAINING ACCURACY:  0.93895\n",
      "EPOCH :  69  LOSS_VALUE :  0.41172781074823783  TRAINING ACCURACY:  0.93995\n",
      "EPOCH :  70  LOSS_VALUE :  0.3559402818151071  TRAINING ACCURACY:  0.9267\n",
      "EPOCH :  71  LOSS_VALUE :  0.36814461471625526  TRAINING ACCURACY:  0.9253\n",
      "EPOCH :  72  LOSS_VALUE :  0.6660601840458048  TRAINING ACCURACY:  0.89635\n",
      "EPOCH :  73  LOSS_VALUE :  1.2600918576962399  TRAINING ACCURACY:  0.8304\n",
      "EPOCH :  74  LOSS_VALUE :  1.3985026611196656  TRAINING ACCURACY:  0.90275\n",
      "EPOCH :  75  LOSS_VALUE :  0.9492006724689233  TRAINING ACCURACY:  0.92155\n",
      "EPOCH :  76  LOSS_VALUE :  0.5287325131656145  TRAINING ACCURACY:  0.9486\n",
      "EPOCH :  77  LOSS_VALUE :  0.4728368144248409  TRAINING ACCURACY:  0.947\n",
      "EPOCH :  78  LOSS_VALUE :  0.42556049119475275  TRAINING ACCURACY:  0.9465\n",
      "EPOCH :  79  LOSS_VALUE :  0.37466254268866445  TRAINING ACCURACY:  0.94935\n",
      "EPOCH :  80  LOSS_VALUE :  0.3281871794538662  TRAINING ACCURACY:  0.9497\n",
      "EPOCH :  81  LOSS_VALUE :  0.29908967160981004  TRAINING ACCURACY:  0.94925\n",
      "EPOCH :  82  LOSS_VALUE :  0.2752919214877261  TRAINING ACCURACY:  0.9482\n",
      "EPOCH :  83  LOSS_VALUE :  0.2629949398825486  TRAINING ACCURACY:  0.946\n",
      "EPOCH :  84  LOSS_VALUE :  0.25681876630597367  TRAINING ACCURACY:  0.9459\n",
      "EPOCH :  85  LOSS_VALUE :  0.2515629173361904  TRAINING ACCURACY:  0.9453\n",
      "EPOCH :  86  LOSS_VALUE :  0.24766991058831614  TRAINING ACCURACY:  0.946\n",
      "EPOCH :  87  LOSS_VALUE :  0.244588993767572  TRAINING ACCURACY:  0.94415\n",
      "EPOCH :  88  LOSS_VALUE :  0.24540615756361267  TRAINING ACCURACY:  0.93895\n",
      "EPOCH :  89  LOSS_VALUE :  0.2670929879403237  TRAINING ACCURACY:  0.9411\n",
      "EPOCH :  90  LOSS_VALUE :  0.34495675677281173  TRAINING ACCURACY:  0.92675\n",
      "EPOCH :  91  LOSS_VALUE :  0.4911946383983954  TRAINING ACCURACY:  0.93445\n",
      "EPOCH :  92  LOSS_VALUE :  0.5149415475886356  TRAINING ACCURACY:  0.92505\n",
      "EPOCH :  93  LOSS_VALUE :  0.4209316999552991  TRAINING ACCURACY:  0.9432\n",
      "EPOCH :  94  LOSS_VALUE :  0.33594550268652523  TRAINING ACCURACY:  0.9405\n",
      "EPOCH :  95  LOSS_VALUE :  0.29466709096065624  TRAINING ACCURACY:  0.951\n",
      "EPOCH :  96  LOSS_VALUE :  0.260757931181989  TRAINING ACCURACY:  0.94485\n",
      "EPOCH :  97  LOSS_VALUE :  0.2541208562221477  TRAINING ACCURACY:  0.95025\n",
      "EPOCH :  98  LOSS_VALUE :  0.2512431111563001  TRAINING ACCURACY:  0.9417\n",
      "EPOCH :  99  LOSS_VALUE :  0.26402141951002156  TRAINING ACCURACY:  0.94745\n",
      "EPOCH :  100  LOSS_VALUE :  0.27938204167167263  TRAINING ACCURACY:  0.93755\n",
      "EPOCH :  101  LOSS_VALUE :  0.30678538289219043  TRAINING ACCURACY:  0.9459\n",
      "EPOCH :  102  LOSS_VALUE :  0.29393354696292334  TRAINING ACCURACY:  0.93805\n",
      "EPOCH :  103  LOSS_VALUE :  0.2950705850259423  TRAINING ACCURACY:  0.949\n",
      "EPOCH :  104  LOSS_VALUE :  0.26996802038516743  TRAINING ACCURACY:  0.94075\n",
      "EPOCH :  105  LOSS_VALUE :  0.26994534739715687  TRAINING ACCURACY:  0.95055\n",
      "EPOCH :  106  LOSS_VALUE :  0.25126926709439584  TRAINING ACCURACY:  0.9416\n",
      "EPOCH :  107  LOSS_VALUE :  0.2579657369572825  TRAINING ACCURACY:  0.95135\n",
      "EPOCH :  108  LOSS_VALUE :  0.24605725653049018  TRAINING ACCURACY:  0.9418\n",
      "EPOCH :  109  LOSS_VALUE :  0.2540911787140213  TRAINING ACCURACY:  0.9515\n",
      "EPOCH :  110  LOSS_VALUE :  0.24381752980660054  TRAINING ACCURACY:  0.94195\n",
      "EPOCH :  111  LOSS_VALUE :  0.2516383930618701  TRAINING ACCURACY:  0.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  112  LOSS_VALUE :  0.24181462280370752  TRAINING ACCURACY:  0.9425\n",
      "EPOCH :  113  LOSS_VALUE :  0.24941714532876955  TRAINING ACCURACY:  0.95175\n",
      "EPOCH :  114  LOSS_VALUE :  0.24000323290489134  TRAINING ACCURACY:  0.94275\n",
      "EPOCH :  115  LOSS_VALUE :  0.24754796845195465  TRAINING ACCURACY:  0.95205\n",
      "EPOCH :  116  LOSS_VALUE :  0.23825104549672232  TRAINING ACCURACY:  0.94325\n",
      "EPOCH :  117  LOSS_VALUE :  0.2454535486890405  TRAINING ACCURACY:  0.95235\n",
      "EPOCH :  118  LOSS_VALUE :  0.2360926004030019  TRAINING ACCURACY:  0.94375\n",
      "EPOCH :  119  LOSS_VALUE :  0.24232040050664383  TRAINING ACCURACY:  0.95295\n",
      "EPOCH :  120  LOSS_VALUE :  0.23298661369166163  TRAINING ACCURACY:  0.9444\n",
      "EPOCH :  121  LOSS_VALUE :  0.23815860256737234  TRAINING ACCURACY:  0.9531\n",
      "EPOCH :  122  LOSS_VALUE :  0.2292956551364871  TRAINING ACCURACY:  0.945\n",
      "EPOCH :  123  LOSS_VALUE :  0.23385154655635698  TRAINING ACCURACY:  0.9535\n",
      "EPOCH :  124  LOSS_VALUE :  0.22572752414859748  TRAINING ACCURACY:  0.9455\n",
      "EPOCH :  125  LOSS_VALUE :  0.23010761030552132  TRAINING ACCURACY:  0.9538\n",
      "EPOCH :  126  LOSS_VALUE :  0.22301513081809013  TRAINING ACCURACY:  0.94575\n",
      "EPOCH :  127  LOSS_VALUE :  0.2277265298454398  TRAINING ACCURACY:  0.954\n",
      "EPOCH :  128  LOSS_VALUE :  0.2219115710802576  TRAINING ACCURACY:  0.9458\n",
      "EPOCH :  129  LOSS_VALUE :  0.22490032993411088  TRAINING ACCURACY:  0.954\n",
      "EPOCH :  130  LOSS_VALUE :  0.2199290362706807  TRAINING ACCURACY:  0.9465\n",
      "EPOCH :  131  LOSS_VALUE :  0.22448725874884845  TRAINING ACCURACY:  0.95415\n",
      "EPOCH :  132  LOSS_VALUE :  0.21748577421210494  TRAINING ACCURACY:  0.94695\n",
      "EPOCH :  133  LOSS_VALUE :  0.21952727939856329  TRAINING ACCURACY:  0.95455\n",
      "EPOCH :  134  LOSS_VALUE :  0.21448731180118386  TRAINING ACCURACY:  0.94775\n",
      "EPOCH :  135  LOSS_VALUE :  0.21669996380153347  TRAINING ACCURACY:  0.9549\n",
      "EPOCH :  136  LOSS_VALUE :  0.2125108366806036  TRAINING ACCURACY:  0.94785\n",
      "EPOCH :  137  LOSS_VALUE :  0.2148121088046506  TRAINING ACCURACY:  0.955\n",
      "EPOCH :  138  LOSS_VALUE :  0.2106122541580252  TRAINING ACCURACY:  0.9483\n",
      "EPOCH :  139  LOSS_VALUE :  0.21197643613739917  TRAINING ACCURACY:  0.9554\n",
      "EPOCH :  140  LOSS_VALUE :  0.208685186232447  TRAINING ACCURACY:  0.94845\n",
      "EPOCH :  141  LOSS_VALUE :  0.20991309638928998  TRAINING ACCURACY:  0.95575\n",
      "EPOCH :  142  LOSS_VALUE :  0.20699708179063073  TRAINING ACCURACY:  0.94865\n",
      "EPOCH :  143  LOSS_VALUE :  0.20811880751680667  TRAINING ACCURACY:  0.9559\n",
      "EPOCH :  144  LOSS_VALUE :  0.2053585238595052  TRAINING ACCURACY:  0.9489\n",
      "EPOCH :  145  LOSS_VALUE :  0.20618569297157635  TRAINING ACCURACY:  0.95595\n",
      "EPOCH :  146  LOSS_VALUE :  0.20345206740843824  TRAINING ACCURACY:  0.94935\n",
      "EPOCH :  147  LOSS_VALUE :  0.2038800500972826  TRAINING ACCURACY:  0.9563\n",
      "EPOCH :  148  LOSS_VALUE :  0.20114934038698068  TRAINING ACCURACY:  0.9497\n",
      "EPOCH :  149  LOSS_VALUE :  0.20126825607574175  TRAINING ACCURACY:  0.9564\n",
      "EPOCH :  150  LOSS_VALUE :  0.1987123326551393  TRAINING ACCURACY:  0.94985\n",
      "EPOCH :  151  LOSS_VALUE :  0.198693074197452  TRAINING ACCURACY:  0.9567\n",
      "EPOCH :  152  LOSS_VALUE :  0.1963289629472571  TRAINING ACCURACY:  0.951\n",
      "EPOCH :  153  LOSS_VALUE :  0.19630425253199638  TRAINING ACCURACY:  0.95685\n",
      "EPOCH :  154  LOSS_VALUE :  0.19403630408303502  TRAINING ACCURACY:  0.9512\n",
      "EPOCH :  155  LOSS_VALUE :  0.19411976944725973  TRAINING ACCURACY:  0.95715\n",
      "EPOCH :  156  LOSS_VALUE :  0.19205618326185908  TRAINING ACCURACY:  0.95155\n",
      "EPOCH :  157  LOSS_VALUE :  0.19225263070071558  TRAINING ACCURACY:  0.9573\n",
      "EPOCH :  158  LOSS_VALUE :  0.1903083519610555  TRAINING ACCURACY:  0.9518\n",
      "EPOCH :  159  LOSS_VALUE :  0.19047436951404872  TRAINING ACCURACY:  0.9574\n",
      "EPOCH :  160  LOSS_VALUE :  0.18856804596002374  TRAINING ACCURACY:  0.95215\n",
      "EPOCH :  161  LOSS_VALUE :  0.18857400614454845  TRAINING ACCURACY:  0.95765\n",
      "EPOCH :  162  LOSS_VALUE :  0.18673475125921116  TRAINING ACCURACY:  0.9526\n",
      "EPOCH :  163  LOSS_VALUE :  0.18661697815502098  TRAINING ACCURACY:  0.95785\n",
      "EPOCH :  164  LOSS_VALUE :  0.18497897260137566  TRAINING ACCURACY:  0.95285\n",
      "EPOCH :  165  LOSS_VALUE :  0.18479255908497888  TRAINING ACCURACY:  0.9582\n",
      "EPOCH :  166  LOSS_VALUE :  0.1834692933482941  TRAINING ACCURACY:  0.9532\n",
      "EPOCH :  167  LOSS_VALUE :  0.18312883614417422  TRAINING ACCURACY:  0.95825\n",
      "EPOCH :  168  LOSS_VALUE :  0.18210862394884894  TRAINING ACCURACY:  0.95355\n",
      "EPOCH :  169  LOSS_VALUE :  0.1815262723106797  TRAINING ACCURACY:  0.95835\n",
      "EPOCH :  170  LOSS_VALUE :  0.1806411504676238  TRAINING ACCURACY:  0.95395\n",
      "EPOCH :  171  LOSS_VALUE :  0.17981596514274756  TRAINING ACCURACY:  0.95845\n",
      "EPOCH :  172  LOSS_VALUE :  0.17901791407988923  TRAINING ACCURACY:  0.9543\n",
      "EPOCH :  173  LOSS_VALUE :  0.17808692447299757  TRAINING ACCURACY:  0.9586\n",
      "EPOCH :  174  LOSS_VALUE :  0.17737262443010585  TRAINING ACCURACY:  0.95445\n",
      "EPOCH :  175  LOSS_VALUE :  0.17649813050406984  TRAINING ACCURACY:  0.9587\n",
      "EPOCH :  176  LOSS_VALUE :  0.17582026513998408  TRAINING ACCURACY:  0.9547\n",
      "EPOCH :  177  LOSS_VALUE :  0.17502727477294594  TRAINING ACCURACY:  0.95895\n",
      "EPOCH :  178  LOSS_VALUE :  0.17433445375713819  TRAINING ACCURACY:  0.9552\n",
      "EPOCH :  179  LOSS_VALUE :  0.17355995590831816  TRAINING ACCURACY:  0.9591\n",
      "EPOCH :  180  LOSS_VALUE :  0.17281976080813685  TRAINING ACCURACY:  0.9553\n",
      "EPOCH :  181  LOSS_VALUE :  0.17200513885263  TRAINING ACCURACY:  0.95925\n",
      "EPOCH :  182  LOSS_VALUE :  0.17126918977906208  TRAINING ACCURACY:  0.9554\n",
      "EPOCH :  183  LOSS_VALUE :  0.1703981573528887  TRAINING ACCURACY:  0.9594\n",
      "EPOCH :  184  LOSS_VALUE :  0.16972724038496534  TRAINING ACCURACY:  0.95565\n",
      "EPOCH :  185  LOSS_VALUE :  0.16884146861209506  TRAINING ACCURACY:  0.95945\n",
      "EPOCH :  186  LOSS_VALUE :  0.16831662791763033  TRAINING ACCURACY:  0.95585\n",
      "EPOCH :  187  LOSS_VALUE :  0.16751177648962182  TRAINING ACCURACY:  0.9597\n",
      "EPOCH :  188  LOSS_VALUE :  0.16757784624952773  TRAINING ACCURACY:  0.9559\n",
      "EPOCH :  189  LOSS_VALUE :  0.1676996120145795  TRAINING ACCURACY:  0.95935\n",
      "EPOCH :  190  LOSS_VALUE :  0.16735630275919902  TRAINING ACCURACY:  0.95595\n",
      "EPOCH :  191  LOSS_VALUE :  0.16716122979893397  TRAINING ACCURACY:  0.9591\n",
      "EPOCH :  192  LOSS_VALUE :  0.16601659602112923  TRAINING ACCURACY:  0.95645\n",
      "EPOCH :  193  LOSS_VALUE :  0.16404141315064458  TRAINING ACCURACY:  0.96\n",
      "EPOCH :  194  LOSS_VALUE :  0.1636809144224516  TRAINING ACCURACY:  0.9571\n",
      "EPOCH :  195  LOSS_VALUE :  0.16246122376258187  TRAINING ACCURACY:  0.96\n",
      "EPOCH :  196  LOSS_VALUE :  0.16230321758443353  TRAINING ACCURACY:  0.95725\n",
      "EPOCH :  197  LOSS_VALUE :  0.16161250116799583  TRAINING ACCURACY:  0.9601\n",
      "EPOCH :  198  LOSS_VALUE :  0.16144116978709233  TRAINING ACCURACY:  0.95745\n",
      "EPOCH :  199  LOSS_VALUE :  0.16093294822817283  TRAINING ACCURACY:  0.9603\n",
      "EPOCH :  200  LOSS_VALUE :  0.16071438215977685  TRAINING ACCURACY:  0.9576\n",
      "EPOCH :  201  LOSS_VALUE :  0.16025934256735172  TRAINING ACCURACY:  0.96035\n",
      "EPOCH :  202  LOSS_VALUE :  0.16002760956130152  TRAINING ACCURACY:  0.95765\n",
      "EPOCH :  203  LOSS_VALUE :  0.1594248691179612  TRAINING ACCURACY:  0.9603\n",
      "EPOCH :  204  LOSS_VALUE :  0.15909028339369433  TRAINING ACCURACY:  0.9579\n",
      "EPOCH :  205  LOSS_VALUE :  0.15848012793858923  TRAINING ACCURACY:  0.96055\n",
      "EPOCH :  206  LOSS_VALUE :  0.15817249405268718  TRAINING ACCURACY:  0.95785\n",
      "EPOCH :  207  LOSS_VALUE :  0.15755099396831115  TRAINING ACCURACY:  0.9606\n",
      "EPOCH :  208  LOSS_VALUE :  0.1574665927240417  TRAINING ACCURACY:  0.9581\n",
      "EPOCH :  209  LOSS_VALUE :  0.1566045812761331  TRAINING ACCURACY:  0.96065\n",
      "EPOCH :  210  LOSS_VALUE :  0.15648671322253954  TRAINING ACCURACY:  0.95825\n",
      "EPOCH :  211  LOSS_VALUE :  0.15534426158539752  TRAINING ACCURACY:  0.96085\n",
      "EPOCH :  212  LOSS_VALUE :  0.1547981369446212  TRAINING ACCURACY:  0.9587\n",
      "EPOCH :  213  LOSS_VALUE :  0.15408587363887624  TRAINING ACCURACY:  0.96075\n",
      "EPOCH :  214  LOSS_VALUE :  0.15363163822763465  TRAINING ACCURACY:  0.95915\n",
      "EPOCH :  215  LOSS_VALUE :  0.15336346828316083  TRAINING ACCURACY:  0.9607\n",
      "EPOCH :  216  LOSS_VALUE :  0.1531647230134071  TRAINING ACCURACY:  0.95955\n",
      "EPOCH :  217  LOSS_VALUE :  0.1527813075078093  TRAINING ACCURACY:  0.96075\n",
      "EPOCH :  218  LOSS_VALUE :  0.15260943766022306  TRAINING ACCURACY:  0.9597\n",
      "EPOCH :  219  LOSS_VALUE :  0.15204063050168024  TRAINING ACCURACY:  0.9608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  220  LOSS_VALUE :  0.15182595456970552  TRAINING ACCURACY:  0.95965\n",
      "EPOCH :  221  LOSS_VALUE :  0.1510807715301424  TRAINING ACCURACY:  0.96105\n",
      "EPOCH :  222  LOSS_VALUE :  0.15082253124536785  TRAINING ACCURACY:  0.9598\n",
      "EPOCH :  223  LOSS_VALUE :  0.14996392053199817  TRAINING ACCURACY:  0.96115\n",
      "EPOCH :  224  LOSS_VALUE :  0.14978389803577355  TRAINING ACCURACY:  0.95995\n",
      "EPOCH :  225  LOSS_VALUE :  0.14909237952943094  TRAINING ACCURACY:  0.96095\n",
      "EPOCH :  226  LOSS_VALUE :  0.1503043024718031  TRAINING ACCURACY:  0.9598\n",
      "EPOCH :  227  LOSS_VALUE :  0.15203320379200513  TRAINING ACCURACY:  0.9601\n",
      "EPOCH :  228  LOSS_VALUE :  0.1484508889358087  TRAINING ACCURACY:  0.96015\n",
      "EPOCH :  229  LOSS_VALUE :  0.146763141105444  TRAINING ACCURACY:  0.9617\n",
      "EPOCH :  230  LOSS_VALUE :  0.14649765592835934  TRAINING ACCURACY:  0.96045\n",
      "EPOCH :  231  LOSS_VALUE :  0.1454214450502132  TRAINING ACCURACY:  0.96195\n",
      "EPOCH :  232  LOSS_VALUE :  0.1451424042478135  TRAINING ACCURACY:  0.9607\n",
      "EPOCH :  233  LOSS_VALUE :  0.14426069817466147  TRAINING ACCURACY:  0.96205\n",
      "EPOCH :  234  LOSS_VALUE :  0.14397715514524942  TRAINING ACCURACY:  0.96075\n",
      "EPOCH :  235  LOSS_VALUE :  0.1432053539966724  TRAINING ACCURACY:  0.9622\n",
      "EPOCH :  236  LOSS_VALUE :  0.14287509189546121  TRAINING ACCURACY:  0.9609\n",
      "EPOCH :  237  LOSS_VALUE :  0.1421547815953011  TRAINING ACCURACY:  0.96205\n",
      "EPOCH :  238  LOSS_VALUE :  0.14180084087634143  TRAINING ACCURACY:  0.96125\n",
      "EPOCH :  239  LOSS_VALUE :  0.14110501213194115  TRAINING ACCURACY:  0.96215\n",
      "EPOCH :  240  LOSS_VALUE :  0.14076628729926996  TRAINING ACCURACY:  0.96135\n",
      "EPOCH :  241  LOSS_VALUE :  0.1400779996976303  TRAINING ACCURACY:  0.9624\n",
      "EPOCH :  242  LOSS_VALUE :  0.13978452964612453  TRAINING ACCURACY:  0.9615\n",
      "EPOCH :  243  LOSS_VALUE :  0.13910292152399198  TRAINING ACCURACY:  0.9625\n",
      "EPOCH :  244  LOSS_VALUE :  0.13887468533899086  TRAINING ACCURACY:  0.96165\n",
      "EPOCH :  245  LOSS_VALUE :  0.138196464771304  TRAINING ACCURACY:  0.96255\n",
      "EPOCH :  246  LOSS_VALUE :  0.1380293147604826  TRAINING ACCURACY:  0.96195\n",
      "EPOCH :  247  LOSS_VALUE :  0.13734355998448486  TRAINING ACCURACY:  0.96275\n",
      "EPOCH :  248  LOSS_VALUE :  0.13721481968418645  TRAINING ACCURACY:  0.9621\n",
      "EPOCH :  249  LOSS_VALUE :  0.13651552408127163  TRAINING ACCURACY:  0.96295\n",
      "EPOCH :  250  LOSS_VALUE :  0.13640479008190629  TRAINING ACCURACY:  0.9622\n",
      "EPOCH :  251  LOSS_VALUE :  0.1356973462255335  TRAINING ACCURACY:  0.9632\n",
      "EPOCH :  252  LOSS_VALUE :  0.13559303105444412  TRAINING ACCURACY:  0.9623\n",
      "EPOCH :  253  LOSS_VALUE :  0.13488760340366027  TRAINING ACCURACY:  0.9634\n",
      "EPOCH :  254  LOSS_VALUE :  0.1347841091525942  TRAINING ACCURACY:  0.96235\n",
      "EPOCH :  255  LOSS_VALUE :  0.13408919942189487  TRAINING ACCURACY:  0.9635\n",
      "EPOCH :  256  LOSS_VALUE :  0.13398466242595966  TRAINING ACCURACY:  0.96245\n",
      "EPOCH :  257  LOSS_VALUE :  0.13330489981941834  TRAINING ACCURACY:  0.96355\n",
      "EPOCH :  258  LOSS_VALUE :  0.13319981049574584  TRAINING ACCURACY:  0.9625\n",
      "EPOCH :  259  LOSS_VALUE :  0.13253647366246102  TRAINING ACCURACY:  0.96365\n",
      "EPOCH :  260  LOSS_VALUE :  0.13243239625300796  TRAINING ACCURACY:  0.96265\n",
      "EPOCH :  261  LOSS_VALUE :  0.13178511468250897  TRAINING ACCURACY:  0.9637\n",
      "EPOCH :  262  LOSS_VALUE :  0.1316835544079563  TRAINING ACCURACY:  0.9627\n",
      "EPOCH :  263  LOSS_VALUE :  0.13105170331252322  TRAINING ACCURACY:  0.9639\n",
      "EPOCH :  264  LOSS_VALUE :  0.13095333914272986  TRAINING ACCURACY:  0.9627\n",
      "EPOCH :  265  LOSS_VALUE :  0.13033653083960792  TRAINING ACCURACY:  0.9639\n",
      "EPOCH :  266  LOSS_VALUE :  0.13024086969396742  TRAINING ACCURACY:  0.96285\n",
      "EPOCH :  267  LOSS_VALUE :  0.12963885545946605  TRAINING ACCURACY:  0.96395\n",
      "EPOCH :  268  LOSS_VALUE :  0.1295442516885184  TRAINING ACCURACY:  0.963\n",
      "EPOCH :  269  LOSS_VALUE :  0.128956712058987  TRAINING ACCURACY:  0.96395\n",
      "EPOCH :  270  LOSS_VALUE :  0.12886072135947205  TRAINING ACCURACY:  0.9631\n",
      "EPOCH :  271  LOSS_VALUE :  0.12828724633236036  TRAINING ACCURACY:  0.96395\n",
      "EPOCH :  272  LOSS_VALUE :  0.1281873854829928  TRAINING ACCURACY:  0.96325\n",
      "EPOCH :  273  LOSS_VALUE :  0.12762781213828575  TRAINING ACCURACY:  0.964\n",
      "EPOCH :  274  LOSS_VALUE :  0.12752268557703594  TRAINING ACCURACY:  0.9634\n",
      "EPOCH :  275  LOSS_VALUE :  0.1269774399728985  TRAINING ACCURACY:  0.9642\n",
      "EPOCH :  276  LOSS_VALUE :  0.1268671581255444  TRAINING ACCURACY:  0.9637\n",
      "EPOCH :  277  LOSS_VALUE :  0.12633618387842876  TRAINING ACCURACY:  0.9642\n",
      "EPOCH :  278  LOSS_VALUE :  0.1262205376283477  TRAINING ACCURACY:  0.96375\n",
      "EPOCH :  279  LOSS_VALUE :  0.12570136933760315  TRAINING ACCURACY:  0.96425\n",
      "EPOCH :  280  LOSS_VALUE :  0.12557766911176246  TRAINING ACCURACY:  0.96385\n",
      "EPOCH :  281  LOSS_VALUE :  0.12506393158937915  TRAINING ACCURACY:  0.9644\n",
      "EPOCH :  282  LOSS_VALUE :  0.12492253672182943  TRAINING ACCURACY:  0.96395\n",
      "EPOCH :  283  LOSS_VALUE :  0.12439957066955531  TRAINING ACCURACY:  0.9646\n",
      "EPOCH :  284  LOSS_VALUE :  0.12422113976448634  TRAINING ACCURACY:  0.96415\n",
      "EPOCH :  285  LOSS_VALUE :  0.12367207093751872  TRAINING ACCURACY:  0.96485\n",
      "EPOCH :  286  LOSS_VALUE :  0.12343555882954312  TRAINING ACCURACY:  0.9644\n",
      "EPOCH :  287  LOSS_VALUE :  0.12284819006444184  TRAINING ACCURACY:  0.9651\n",
      "EPOCH :  288  LOSS_VALUE :  0.12253647372564326  TRAINING ACCURACY:  0.96465\n",
      "EPOCH :  289  LOSS_VALUE :  0.1219109278685307  TRAINING ACCURACY:  0.9652\n",
      "EPOCH :  290  LOSS_VALUE :  0.12153697659541526  TRAINING ACCURACY:  0.9648\n",
      "EPOCH :  291  LOSS_VALUE :  0.12091195189794751  TRAINING ACCURACY:  0.9654\n",
      "EPOCH :  292  LOSS_VALUE :  0.12052888178796793  TRAINING ACCURACY:  0.9652\n",
      "EPOCH :  293  LOSS_VALUE :  0.11994671075862333  TRAINING ACCURACY:  0.9659\n",
      "EPOCH :  294  LOSS_VALUE :  0.11958459096492281  TRAINING ACCURACY:  0.96545\n",
      "EPOCH :  295  LOSS_VALUE :  0.11904933763225786  TRAINING ACCURACY:  0.9659\n",
      "EPOCH :  296  LOSS_VALUE :  0.11871009433477821  TRAINING ACCURACY:  0.96555\n",
      "EPOCH :  297  LOSS_VALUE :  0.11820901751716417  TRAINING ACCURACY:  0.96605\n",
      "EPOCH :  298  LOSS_VALUE :  0.11788393367805511  TRAINING ACCURACY:  0.96585\n",
      "EPOCH :  299  LOSS_VALUE :  0.11740090074227279  TRAINING ACCURACY:  0.9664\n",
      "EPOCH :  300  LOSS_VALUE :  0.1170817473198836  TRAINING ACCURACY:  0.96625\n",
      "EPOCH :  301  LOSS_VALUE :  0.11660891825655516  TRAINING ACCURACY:  0.9667\n",
      "EPOCH :  302  LOSS_VALUE :  0.11629948222900807  TRAINING ACCURACY:  0.9664\n",
      "EPOCH :  303  LOSS_VALUE :  0.11583956379584609  TRAINING ACCURACY:  0.9668\n",
      "EPOCH :  304  LOSS_VALUE :  0.11554372712387272  TRAINING ACCURACY:  0.96655\n",
      "EPOCH :  305  LOSS_VALUE :  0.11509030078786152  TRAINING ACCURACY:  0.96685\n",
      "EPOCH :  306  LOSS_VALUE :  0.1148008908406029  TRAINING ACCURACY:  0.96665\n",
      "EPOCH :  307  LOSS_VALUE :  0.1143479769223031  TRAINING ACCURACY:  0.9671\n",
      "EPOCH :  308  LOSS_VALUE :  0.11406058893002567  TRAINING ACCURACY:  0.9668\n",
      "EPOCH :  309  LOSS_VALUE :  0.1136099306843144  TRAINING ACCURACY:  0.96745\n",
      "EPOCH :  310  LOSS_VALUE :  0.113323556983095  TRAINING ACCURACY:  0.9669\n",
      "EPOCH :  311  LOSS_VALUE :  0.11287951859232051  TRAINING ACCURACY:  0.9675\n",
      "EPOCH :  312  LOSS_VALUE :  0.11259597781159451  TRAINING ACCURACY:  0.96715\n",
      "EPOCH :  313  LOSS_VALUE :  0.11216112681810014  TRAINING ACCURACY:  0.9674\n",
      "EPOCH :  314  LOSS_VALUE :  0.11188466546848642  TRAINING ACCURACY:  0.9673\n",
      "EPOCH :  315  LOSS_VALUE :  0.11145997768822168  TRAINING ACCURACY:  0.9676\n",
      "EPOCH :  316  LOSS_VALUE :  0.11119504951100706  TRAINING ACCURACY:  0.96745\n",
      "EPOCH :  317  LOSS_VALUE :  0.11078078963640517  TRAINING ACCURACY:  0.9677\n",
      "EPOCH :  318  LOSS_VALUE :  0.11052967240875258  TRAINING ACCURACY:  0.96765\n",
      "EPOCH :  319  LOSS_VALUE :  0.11012519010569859  TRAINING ACCURACY:  0.9679\n",
      "EPOCH :  320  LOSS_VALUE :  0.10988760606374019  TRAINING ACCURACY:  0.96785\n",
      "EPOCH :  321  LOSS_VALUE :  0.10949169000239649  TRAINING ACCURACY:  0.9681\n",
      "EPOCH :  322  LOSS_VALUE :  0.10926612310413214  TRAINING ACCURACY:  0.96795\n",
      "EPOCH :  323  LOSS_VALUE :  0.10887801932315493  TRAINING ACCURACY:  0.9684\n",
      "EPOCH :  324  LOSS_VALUE :  0.10866288000507524  TRAINING ACCURACY:  0.968\n",
      "EPOCH :  325  LOSS_VALUE :  0.10828241930357213  TRAINING ACCURACY:  0.96845\n",
      "EPOCH :  326  LOSS_VALUE :  0.10807589132601828  TRAINING ACCURACY:  0.968\n",
      "EPOCH :  327  LOSS_VALUE :  0.10770264351740803  TRAINING ACCURACY:  0.9687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  328  LOSS_VALUE :  0.10750222542718475  TRAINING ACCURACY:  0.9682\n",
      "EPOCH :  329  LOSS_VALUE :  0.10713512109259864  TRAINING ACCURACY:  0.96875\n",
      "EPOCH :  330  LOSS_VALUE :  0.10693793835386312  TRAINING ACCURACY:  0.96825\n",
      "EPOCH :  331  LOSS_VALUE :  0.10657560034973185  TRAINING ACCURACY:  0.9687\n",
      "EPOCH :  332  LOSS_VALUE :  0.10637895231442945  TRAINING ACCURACY:  0.9684\n",
      "EPOCH :  333  LOSS_VALUE :  0.10601996912799369  TRAINING ACCURACY:  0.9687\n",
      "EPOCH :  334  LOSS_VALUE :  0.1058214661708786  TRAINING ACCURACY:  0.96855\n",
      "EPOCH :  335  LOSS_VALUE :  0.10546429079357822  TRAINING ACCURACY:  0.96875\n",
      "EPOCH :  336  LOSS_VALUE :  0.1052615720375894  TRAINING ACCURACY:  0.96855\n",
      "EPOCH :  337  LOSS_VALUE :  0.10490415862719045  TRAINING ACCURACY:  0.9689\n",
      "EPOCH :  338  LOSS_VALUE :  0.10469444453402846  TRAINING ACCURACY:  0.96855\n",
      "EPOCH :  339  LOSS_VALUE :  0.10433388054727132  TRAINING ACCURACY:  0.96905\n",
      "EPOCH :  340  LOSS_VALUE :  0.10411382116548544  TRAINING ACCURACY:  0.9687\n",
      "EPOCH :  341  LOSS_VALUE :  0.10374663609284195  TRAINING ACCURACY:  0.9692\n",
      "EPOCH :  342  LOSS_VALUE :  0.10351370697675953  TRAINING ACCURACY:  0.9688\n",
      "EPOCH :  343  LOSS_VALUE :  0.10313852694439168  TRAINING ACCURACY:  0.9694\n",
      "EPOCH :  344  LOSS_VALUE :  0.102895431530915  TRAINING ACCURACY:  0.96875\n",
      "EPOCH :  345  LOSS_VALUE :  0.10251721806429037  TRAINING ACCURACY:  0.9695\n",
      "EPOCH :  346  LOSS_VALUE :  0.10227281151296932  TRAINING ACCURACY:  0.9687\n",
      "EPOCH :  347  LOSS_VALUE :  0.10189915099873374  TRAINING ACCURACY:  0.96965\n",
      "EPOCH :  348  LOSS_VALUE :  0.10165732484827729  TRAINING ACCURACY:  0.9688\n",
      "EPOCH :  349  LOSS_VALUE :  0.10129193596787639  TRAINING ACCURACY:  0.96965\n",
      "EPOCH :  350  LOSS_VALUE :  0.1010514011865201  TRAINING ACCURACY:  0.9689\n",
      "EPOCH :  351  LOSS_VALUE :  0.10069655728685503  TRAINING ACCURACY:  0.9698\n",
      "EPOCH :  352  LOSS_VALUE :  0.10045820385946819  TRAINING ACCURACY:  0.9691\n",
      "EPOCH :  353  LOSS_VALUE :  0.1001143432975773  TRAINING ACCURACY:  0.97\n",
      "EPOCH :  354  LOSS_VALUE :  0.09987763993687415  TRAINING ACCURACY:  0.9691\n",
      "EPOCH :  355  LOSS_VALUE :  0.09954292829465625  TRAINING ACCURACY:  0.97015\n",
      "EPOCH :  356  LOSS_VALUE :  0.09930591073982424  TRAINING ACCURACY:  0.96925\n",
      "EPOCH :  357  LOSS_VALUE :  0.0989775659088278  TRAINING ACCURACY:  0.9701\n",
      "EPOCH :  358  LOSS_VALUE :  0.09873862028532154  TRAINING ACCURACY:  0.96925\n",
      "EPOCH :  359  LOSS_VALUE :  0.09841356782594586  TRAINING ACCURACY:  0.97025\n",
      "EPOCH :  360  LOSS_VALUE :  0.09817162593421785  TRAINING ACCURACY:  0.9694\n",
      "EPOCH :  361  LOSS_VALUE :  0.09784546688564741  TRAINING ACCURACY:  0.97045\n",
      "EPOCH :  362  LOSS_VALUE :  0.09759972984891901  TRAINING ACCURACY:  0.96925\n",
      "EPOCH :  363  LOSS_VALUE :  0.09726682599298994  TRAINING ACCURACY:  0.9704\n",
      "EPOCH :  364  LOSS_VALUE :  0.09701964117869438  TRAINING ACCURACY:  0.9692\n",
      "EPOCH :  365  LOSS_VALUE :  0.09668945911730474  TRAINING ACCURACY:  0.97035\n",
      "EPOCH :  366  LOSS_VALUE :  0.09647574438709451  TRAINING ACCURACY:  0.9693\n",
      "EPOCH :  367  LOSS_VALUE :  0.09625851426232011  TRAINING ACCURACY:  0.97045\n",
      "EPOCH :  368  LOSS_VALUE :  0.09605824912620786  TRAINING ACCURACY:  0.96935\n",
      "EPOCH :  369  LOSS_VALUE :  0.09587512487297173  TRAINING ACCURACY:  0.97045\n",
      "EPOCH :  370  LOSS_VALUE :  0.09558248217590291  TRAINING ACCURACY:  0.96945\n",
      "EPOCH :  371  LOSS_VALUE :  0.09534483507465348  TRAINING ACCURACY:  0.97055\n",
      "EPOCH :  372  LOSS_VALUE :  0.09507476808531329  TRAINING ACCURACY:  0.9696\n",
      "EPOCH :  373  LOSS_VALUE :  0.09480266164172277  TRAINING ACCURACY:  0.97065\n",
      "EPOCH :  374  LOSS_VALUE :  0.09458868113388062  TRAINING ACCURACY:  0.96985\n",
      "EPOCH :  375  LOSS_VALUE :  0.0942946642633122  TRAINING ACCURACY:  0.97065\n",
      "EPOCH :  376  LOSS_VALUE :  0.09408781958568452  TRAINING ACCURACY:  0.96995\n",
      "EPOCH :  377  LOSS_VALUE :  0.09379083887928544  TRAINING ACCURACY:  0.9708\n",
      "EPOCH :  378  LOSS_VALUE :  0.09356883154773375  TRAINING ACCURACY:  0.97015\n",
      "EPOCH :  379  LOSS_VALUE :  0.09329333015861474  TRAINING ACCURACY:  0.97095\n",
      "EPOCH :  380  LOSS_VALUE :  0.0930684003154521  TRAINING ACCURACY:  0.97015\n",
      "EPOCH :  381  LOSS_VALUE :  0.09281469001623603  TRAINING ACCURACY:  0.971\n",
      "EPOCH :  382  LOSS_VALUE :  0.09259347039503474  TRAINING ACCURACY:  0.9703\n",
      "EPOCH :  383  LOSS_VALUE :  0.09235597213332938  TRAINING ACCURACY:  0.97115\n",
      "EPOCH :  384  LOSS_VALUE :  0.09213688821385159  TRAINING ACCURACY:  0.9702\n",
      "EPOCH :  385  LOSS_VALUE :  0.09192201247744036  TRAINING ACCURACY:  0.97135\n",
      "EPOCH :  386  LOSS_VALUE :  0.09169940738230896  TRAINING ACCURACY:  0.97025\n",
      "EPOCH :  387  LOSS_VALUE :  0.09153181909315146  TRAINING ACCURACY:  0.9715\n",
      "EPOCH :  388  LOSS_VALUE :  0.0912784354984693  TRAINING ACCURACY:  0.9702\n",
      "EPOCH :  389  LOSS_VALUE :  0.09117943569354667  TRAINING ACCURACY:  0.97135\n",
      "EPOCH :  390  LOSS_VALUE :  0.09085364615904376  TRAINING ACCURACY:  0.97025\n",
      "EPOCH :  391  LOSS_VALUE :  0.09079102100921253  TRAINING ACCURACY:  0.9713\n",
      "EPOCH :  392  LOSS_VALUE :  0.09040821598147768  TRAINING ACCURACY:  0.97035\n",
      "EPOCH :  393  LOSS_VALUE :  0.09034962234460586  TRAINING ACCURACY:  0.9714\n",
      "EPOCH :  394  LOSS_VALUE :  0.08997305526731729  TRAINING ACCURACY:  0.9704\n",
      "EPOCH :  395  LOSS_VALUE :  0.08997405126823042  TRAINING ACCURACY:  0.9713\n",
      "EPOCH :  396  LOSS_VALUE :  0.08954604097605395  TRAINING ACCURACY:  0.97055\n",
      "EPOCH :  397  LOSS_VALUE :  0.08961502789174024  TRAINING ACCURACY:  0.9715\n",
      "EPOCH :  398  LOSS_VALUE :  0.08910608344332134  TRAINING ACCURACY:  0.9706\n",
      "EPOCH :  399  LOSS_VALUE :  0.08920783102685485  TRAINING ACCURACY:  0.97155\n",
      "EPOCH :  400  LOSS_VALUE :  0.08866970002371584  TRAINING ACCURACY:  0.97095\n",
      "EPOCH :  401  LOSS_VALUE :  0.0888228024761124  TRAINING ACCURACY:  0.9715\n",
      "EPOCH :  402  LOSS_VALUE :  0.08826102725010446  TRAINING ACCURACY:  0.9711\n",
      "EPOCH :  403  LOSS_VALUE :  0.0884781310783461  TRAINING ACCURACY:  0.9714\n",
      "EPOCH :  404  LOSS_VALUE :  0.08787924525732126  TRAINING ACCURACY:  0.9712\n",
      "EPOCH :  405  LOSS_VALUE :  0.0881233940558764  TRAINING ACCURACY:  0.97145\n",
      "EPOCH :  406  LOSS_VALUE :  0.08752022710580434  TRAINING ACCURACY:  0.97145\n",
      "EPOCH :  407  LOSS_VALUE :  0.08776822623659375  TRAINING ACCURACY:  0.97155\n",
      "EPOCH :  408  LOSS_VALUE :  0.0871871413876346  TRAINING ACCURACY:  0.9716\n",
      "EPOCH :  409  LOSS_VALUE :  0.08744008431821403  TRAINING ACCURACY:  0.9715\n",
      "EPOCH :  410  LOSS_VALUE :  0.08687190178494246  TRAINING ACCURACY:  0.97185\n",
      "EPOCH :  411  LOSS_VALUE :  0.08711727537220061  TRAINING ACCURACY:  0.97165\n",
      "EPOCH :  412  LOSS_VALUE :  0.0865658559973946  TRAINING ACCURACY:  0.972\n",
      "EPOCH :  413  LOSS_VALUE :  0.08678850540408851  TRAINING ACCURACY:  0.9717\n",
      "EPOCH :  414  LOSS_VALUE :  0.08626853246518654  TRAINING ACCURACY:  0.9721\n",
      "EPOCH :  415  LOSS_VALUE :  0.0864646787349206  TRAINING ACCURACY:  0.97185\n",
      "EPOCH :  416  LOSS_VALUE :  0.08597666687510787  TRAINING ACCURACY:  0.97215\n",
      "EPOCH :  417  LOSS_VALUE :  0.0861408055584586  TRAINING ACCURACY:  0.97195\n",
      "EPOCH :  418  LOSS_VALUE :  0.08568500503585835  TRAINING ACCURACY:  0.97235\n",
      "EPOCH :  419  LOSS_VALUE :  0.08580858369667448  TRAINING ACCURACY:  0.97215\n",
      "EPOCH :  420  LOSS_VALUE :  0.08538946955221884  TRAINING ACCURACY:  0.97245\n",
      "EPOCH :  421  LOSS_VALUE :  0.0854651210186105  TRAINING ACCURACY:  0.97235\n",
      "EPOCH :  422  LOSS_VALUE :  0.08508570522028903  TRAINING ACCURACY:  0.97255\n",
      "EPOCH :  423  LOSS_VALUE :  0.0851066093729821  TRAINING ACCURACY:  0.9724\n",
      "EPOCH :  424  LOSS_VALUE :  0.08477062330526304  TRAINING ACCURACY:  0.9726\n",
      "EPOCH :  425  LOSS_VALUE :  0.08473281875768426  TRAINING ACCURACY:  0.97265\n",
      "EPOCH :  426  LOSS_VALUE :  0.08444220244502226  TRAINING ACCURACY:  0.97285\n",
      "EPOCH :  427  LOSS_VALUE :  0.08434553269440122  TRAINING ACCURACY:  0.97285\n",
      "EPOCH :  428  LOSS_VALUE :  0.08409216284659851  TRAINING ACCURACY:  0.9731\n",
      "EPOCH :  429  LOSS_VALUE :  0.08393934687406857  TRAINING ACCURACY:  0.97295\n",
      "EPOCH :  430  LOSS_VALUE :  0.08371251847163276  TRAINING ACCURACY:  0.9732\n",
      "EPOCH :  431  LOSS_VALUE :  0.08353691309359743  TRAINING ACCURACY:  0.97295\n",
      "EPOCH :  432  LOSS_VALUE :  0.08336005730259696  TRAINING ACCURACY:  0.9732\n",
      "EPOCH :  433  LOSS_VALUE :  0.08320031585621798  TRAINING ACCURACY:  0.9728\n",
      "EPOCH :  434  LOSS_VALUE :  0.08304635798025005  TRAINING ACCURACY:  0.97335\n",
      "EPOCH :  435  LOSS_VALUE :  0.08289633085772302  TRAINING ACCURACY:  0.9731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  436  LOSS_VALUE :  0.08275118715439012  TRAINING ACCURACY:  0.9734\n",
      "EPOCH :  437  LOSS_VALUE :  0.08260909563090528  TRAINING ACCURACY:  0.97325\n",
      "EPOCH :  438  LOSS_VALUE :  0.08247008442726574  TRAINING ACCURACY:  0.97385\n",
      "EPOCH :  439  LOSS_VALUE :  0.08233285462734131  TRAINING ACCURACY:  0.97325\n",
      "EPOCH :  440  LOSS_VALUE :  0.08219748617137282  TRAINING ACCURACY:  0.974\n",
      "EPOCH :  441  LOSS_VALUE :  0.08206333875871147  TRAINING ACCURACY:  0.9734\n",
      "EPOCH :  442  LOSS_VALUE :  0.08193068580189843  TRAINING ACCURACY:  0.97405\n",
      "EPOCH :  443  LOSS_VALUE :  0.08179922696365541  TRAINING ACCURACY:  0.9736\n",
      "EPOCH :  444  LOSS_VALUE :  0.08166925812241814  TRAINING ACCURACY:  0.97425\n",
      "EPOCH :  445  LOSS_VALUE :  0.08154059039709538  TRAINING ACCURACY:  0.97365\n",
      "EPOCH :  446  LOSS_VALUE :  0.0814134352332523  TRAINING ACCURACY:  0.9743\n",
      "EPOCH :  447  LOSS_VALUE :  0.08128761981024075  TRAINING ACCURACY:  0.97365\n",
      "EPOCH :  448  LOSS_VALUE :  0.08116325815493619  TRAINING ACCURACY:  0.97455\n",
      "EPOCH :  449  LOSS_VALUE :  0.08104018259626464  TRAINING ACCURACY:  0.9737\n",
      "EPOCH :  450  LOSS_VALUE :  0.08091843599627997  TRAINING ACCURACY:  0.9746\n",
      "EPOCH :  451  LOSS_VALUE :  0.08079786436821472  TRAINING ACCURACY:  0.9738\n",
      "EPOCH :  452  LOSS_VALUE :  0.08067846198201543  TRAINING ACCURACY:  0.97505\n",
      "EPOCH :  453  LOSS_VALUE :  0.0805600879506561  TRAINING ACCURACY:  0.9739\n",
      "EPOCH :  454  LOSS_VALUE :  0.08044269825522724  TRAINING ACCURACY:  0.97515\n",
      "EPOCH :  455  LOSS_VALUE :  0.0803261560514889  TRAINING ACCURACY:  0.97405\n",
      "EPOCH :  456  LOSS_VALUE :  0.08021038153063051  TRAINING ACCURACY:  0.97465\n",
      "EPOCH :  457  LOSS_VALUE :  0.0800952295939117  TRAINING ACCURACY:  0.97405\n",
      "EPOCH :  458  LOSS_VALUE :  0.07998058164322702  TRAINING ACCURACY:  0.9745\n",
      "EPOCH :  459  LOSS_VALUE :  0.07986626850302542  TRAINING ACCURACY:  0.97395\n",
      "EPOCH :  460  LOSS_VALUE :  0.07975212077198811  TRAINING ACCURACY:  0.9744\n",
      "EPOCH :  461  LOSS_VALUE :  0.07963791871904183  TRAINING ACCURACY:  0.97405\n",
      "EPOCH :  462  LOSS_VALUE :  0.07952341036433262  TRAINING ACCURACY:  0.9744\n",
      "EPOCH :  463  LOSS_VALUE :  0.07940827107534348  TRAINING ACCURACY:  0.97415\n",
      "EPOCH :  464  LOSS_VALUE :  0.07929208844272478  TRAINING ACCURACY:  0.97455\n",
      "EPOCH :  465  LOSS_VALUE :  0.07917430680470058  TRAINING ACCURACY:  0.9742\n",
      "EPOCH :  466  LOSS_VALUE :  0.07905415510826132  TRAINING ACCURACY:  0.97445\n",
      "EPOCH :  467  LOSS_VALUE :  0.07893051623100232  TRAINING ACCURACY:  0.97415\n",
      "EPOCH :  468  LOSS_VALUE :  0.07880169916268913  TRAINING ACCURACY:  0.97445\n",
      "EPOCH :  469  LOSS_VALUE :  0.07866503141953712  TRAINING ACCURACY:  0.97415\n",
      "EPOCH :  470  LOSS_VALUE :  0.07851609824100045  TRAINING ACCURACY:  0.9744\n",
      "EPOCH :  471  LOSS_VALUE :  0.07834737484622822  TRAINING ACCURACY:  0.9741\n",
      "EPOCH :  472  LOSS_VALUE :  0.07814610146595052  TRAINING ACCURACY:  0.97435\n",
      "EPOCH :  473  LOSS_VALUE :  0.07789328113317037  TRAINING ACCURACY:  0.9742\n",
      "EPOCH :  474  LOSS_VALUE :  0.07757443837983126  TRAINING ACCURACY:  0.97445\n",
      "EPOCH :  475  LOSS_VALUE :  0.07721490232340299  TRAINING ACCURACY:  0.9743\n",
      "EPOCH :  476  LOSS_VALUE :  0.07687831170230297  TRAINING ACCURACY:  0.97445\n",
      "EPOCH :  477  LOSS_VALUE :  0.07659762911974242  TRAINING ACCURACY:  0.97455\n",
      "EPOCH :  478  LOSS_VALUE :  0.07637095103217144  TRAINING ACCURACY:  0.97675\n",
      "EPOCH :  479  LOSS_VALUE :  0.07618630243687746  TRAINING ACCURACY:  0.97475\n",
      "EPOCH :  480  LOSS_VALUE :  0.0760266395211374  TRAINING ACCURACY:  0.9768\n",
      "EPOCH :  481  LOSS_VALUE :  0.07587920284462975  TRAINING ACCURACY:  0.97475\n",
      "EPOCH :  482  LOSS_VALUE :  0.07573757585355216  TRAINING ACCURACY:  0.975\n",
      "EPOCH :  483  LOSS_VALUE :  0.07559864038782835  TRAINING ACCURACY:  0.9747\n",
      "EPOCH :  484  LOSS_VALUE :  0.07546094860662028  TRAINING ACCURACY:  0.97505\n",
      "EPOCH :  485  LOSS_VALUE :  0.07532412295651963  TRAINING ACCURACY:  0.9749\n",
      "EPOCH :  486  LOSS_VALUE :  0.0751886128321444  TRAINING ACCURACY:  0.97545\n",
      "EPOCH :  487  LOSS_VALUE :  0.07505541763122876  TRAINING ACCURACY:  0.9753\n",
      "EPOCH :  488  LOSS_VALUE :  0.07492549614568597  TRAINING ACCURACY:  0.9774\n",
      "EPOCH :  489  LOSS_VALUE :  0.07479911600838374  TRAINING ACCURACY:  0.97745\n",
      "EPOCH :  490  LOSS_VALUE :  0.07467575357216516  TRAINING ACCURACY:  0.9773\n",
      "EPOCH :  491  LOSS_VALUE :  0.07455463330780515  TRAINING ACCURACY:  0.9774\n",
      "EPOCH :  492  LOSS_VALUE :  0.07443521531375931  TRAINING ACCURACY:  0.97725\n",
      "EPOCH :  493  LOSS_VALUE :  0.07431734057832706  TRAINING ACCURACY:  0.9772\n",
      "EPOCH :  494  LOSS_VALUE :  0.07420114224915056  TRAINING ACCURACY:  0.97735\n",
      "EPOCH :  495  LOSS_VALUE :  0.07408689472983199  TRAINING ACCURACY:  0.9773\n",
      "EPOCH :  496  LOSS_VALUE :  0.07397486257096489  TRAINING ACCURACY:  0.97735\n",
      "EPOCH :  497  LOSS_VALUE :  0.07386520582009791  TRAINING ACCURACY:  0.9774\n",
      "EPOCH :  498  LOSS_VALUE :  0.07375794110987322  TRAINING ACCURACY:  0.97745\n",
      "EPOCH :  499  LOSS_VALUE :  0.07365295924576405  TRAINING ACCURACY:  0.97745\n",
      "EPOCH :  500  LOSS_VALUE :  0.07355006469196565  TRAINING ACCURACY:  0.97745\n"
     ]
    }
   ],
   "source": [
    "# To train run the following\n",
    "W1,b1,W2,b2= rand_weights()\n",
    "loss_list,Weights1,bias1,Weights2,bias2= train(0.001,500,X_train,Y_train,W1,b1,W2,b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9728649558266723\n"
     ]
    }
   ],
   "source": [
    "# Testing On validation set\n",
    "\n",
    "y_pred=predict(X_val,Weights1,bias1,Weights2,bias2)\n",
    "acc=accuracy(Y_val,y_pred)\n",
    "\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STORING THE WEIGHTS IN PICKLE FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved data to \n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "pkl.dump({\"W1\": Weights1, \"b1\": bias1, \"W2\": Weights2, \"b2\": bias2}, open(\"model_weights.pkl\", \"wb\"))\n",
    "print(\"saved data to \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READING THE STORED WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_dict= pkl.load(open(\"model_weights.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Softmax is used as final layer activation function. \n",
    "\n",
    "softmax or sigmoid can be used as final layer activation function for multiclass classifier but softmax is commonly used when the probabilities produced for each class is dependant and the sum of probablities corresponds to 1. (i.e) more prefered when there is only one ouput from multiclass which is similar to one hot encoded output.Hence softmax is used for the final layer activation function\n",
    "\n",
    "2) Sigmoid used as activation function in the middle layer.\n",
    "\n",
    "Sigmoid may not work properly as it might lead to vanishing gradient when the number of hidden layers are more but since here there is just one hidden layer sigmoid activation is chosen.\n",
    "\n",
    "3) Categorical cross Loss function is used as cost function.\n",
    "\n",
    " Since it is a multiclass classification problem espicially with outputs as categorical (i.e) one hot encoded, categorical cross entropy is used.\n",
    " \n",
    "4) Hidden Neurons selection\n",
    "\n",
    "Since the dataset is fairly small with less samples and the features being easily learnt when trained, I have added hidden neuron as 112 , which can itself learn the essential feature and classify the output.\n",
    "\n",
    "5) Learning rate and train_test_split\n",
    "\n",
    "Since samples in the dataset was comparitively less and more samples to training would help the model learn, I have choosen 20000 samples for training and 4754 samples for validation.I varied the learning rate, and found the learning rate with 0.001 was optimal and produced a validation accuracy of over 97%.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
